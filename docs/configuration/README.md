# Configuration Options

This section lists the most common options for running vLLM.

There are three main levels of configuration, from highest priority to lowest priority:

- [Request parameters][completions-api] and [input arguments][sampling-params]
- [Engine arguments](./engine_args.md)
- [Environment variables](./env_vars.md)

## Configuration Guides

- [Model Conversion](./model_conversion.md) - How to use ConvertOption to adapt models for different tasks
- [Model Resolution](./model_resolution.md) - How vLLM resolves and loads models
- [Memory Conservation](./conserving_memory.md) - Strategies for optimizing memory usage
- [Performance Optimization](./optimization.md) - Tips for improving inference performance
